{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"machine_shape":"hm","gpuType":"T4","provenance":[]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"554213b2b5cf4dd386fda7fcc8d4c24c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cdaa3cf060034551bd054b307c7703a2","IPY_MODEL_3c51de8e2b9d437895e1a1d4cfb6c0d6","IPY_MODEL_d6ddc9d3673f4381816c6f5d2ecfe691"],"layout":"IPY_MODEL_71438e4b1841460c9e39386559f5cf4b"}},"cdaa3cf060034551bd054b307c7703a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91387783687b4e7088780aa6686daf3b","placeholder":"‚Äã","style":"IPY_MODEL_06635ee354384365a4975d92fb378421","value":"tokenizer_config.json:‚Äá100%"}},"3c51de8e2b9d437895e1a1d4cfb6c0d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d541d27dd79c470da7cc261526a0892b","max":2537,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a0ce921159943a7a05fddcdcae02d6f","value":2537}},"d6ddc9d3673f4381816c6f5d2ecfe691":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5604e41686924130b8c6eba9e07b772e","placeholder":"‚Äã","style":"IPY_MODEL_ea1a026e28174c6385fbe63116d1bd78","value":"‚Äá2.54k/2.54k‚Äá[00:00&lt;00:00,‚Äá77.0kB/s]"}},"71438e4b1841460c9e39386559f5cf4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91387783687b4e7088780aa6686daf3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06635ee354384365a4975d92fb378421":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d541d27dd79c470da7cc261526a0892b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a0ce921159943a7a05fddcdcae02d6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5604e41686924130b8c6eba9e07b772e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1a026e28174c6385fbe63116d1bd78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff03ec31f7af47219ce89d0468327bb5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65f4fd5a19394a7195cb0af68bc85ce6","IPY_MODEL_22896c1488fd483d9d06061d20df9646","IPY_MODEL_b77e2c40c8cc42b5ab67013c749b5983"],"layout":"IPY_MODEL_ccb3f76116e54a8e98613312520df7c3"}},"65f4fd5a19394a7195cb0af68bc85ce6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e469446a24094c7c81f7ce3c09375470","placeholder":"‚Äã","style":"IPY_MODEL_b211e1844f9c4cae80a92c30816acea3","value":"spiece.model:‚Äá100%"}},"22896c1488fd483d9d06061d20df9646":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e3af8ce958048c8a19fc789b17d31bd","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6a65407d9cd4249a6984136c786397e","value":791656}},"b77e2c40c8cc42b5ab67013c749b5983":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfd6efdcae014720b8926a2d422e6149","placeholder":"‚Äã","style":"IPY_MODEL_a1e8320468f8435fb210aff27537a29c","value":"‚Äá792k/792k‚Äá[00:00&lt;00:00,‚Äá1.23MB/s]"}},"ccb3f76116e54a8e98613312520df7c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e469446a24094c7c81f7ce3c09375470":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b211e1844f9c4cae80a92c30816acea3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e3af8ce958048c8a19fc789b17d31bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6a65407d9cd4249a6984136c786397e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfd6efdcae014720b8926a2d422e6149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1e8320468f8435fb210aff27537a29c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5e3d779e0de4b7e89af4eb4b3affaf6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9915c4e538864e259c3bad7a53383155","IPY_MODEL_4ca84fa7f5954de89f3494cc7ce6ba1d","IPY_MODEL_974cfc5b71834335a408cbeccd2edb96"],"layout":"IPY_MODEL_4fb8543c965c4a36a95822cbf582a7ec"}},"9915c4e538864e259c3bad7a53383155":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c297670187743d8bcc188d9c68b5153","placeholder":"‚Äã","style":"IPY_MODEL_ef2e676991a94b01a4353c3c1a880645","value":"tokenizer.json:‚Äá100%"}},"4ca84fa7f5954de89f3494cc7ce6ba1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f8c96aead8d40ce91fb8327a50193ed","max":2424064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dfcff02f3bbd4173b3426dd2207ae24e","value":2424064}},"974cfc5b71834335a408cbeccd2edb96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c63ecf4d68784a31aeb4a21e1b33f1e1","placeholder":"‚Äã","style":"IPY_MODEL_8a20d607d042434f951f84ade04dac84","value":"‚Äá2.42M/2.42M‚Äá[00:00&lt;00:00,‚Äá10.2MB/s]"}},"4fb8543c965c4a36a95822cbf582a7ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c297670187743d8bcc188d9c68b5153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef2e676991a94b01a4353c3c1a880645":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f8c96aead8d40ce91fb8327a50193ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfcff02f3bbd4173b3426dd2207ae24e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c63ecf4d68784a31aeb4a21e1b33f1e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a20d607d042434f951f84ade04dac84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98ece805e48e45d4b9542c2257b0962f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b84eeb4bc02941e88ea9703f78718e78","IPY_MODEL_f8455a470ec24de29af1dedf5539eb42","IPY_MODEL_aaf375295e204c7e9c55f459ce73f07e"],"layout":"IPY_MODEL_ed02dd976db144b8be813d09c7bf25cc"}},"b84eeb4bc02941e88ea9703f78718e78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a5d0c88d7d74d95aae87f4e6fee4825","placeholder":"‚Äã","style":"IPY_MODEL_ae81904f118c42a897175ca1b17f9369","value":"special_tokens_map.json:‚Äá100%"}},"f8455a470ec24de29af1dedf5539eb42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23d8011b8825449d8b8804cd7de0e512","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68a82ce9b9ed4605bff67569ab9d0456","value":2201}},"aaf375295e204c7e9c55f459ce73f07e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0647de13fa344a8fb48acfa61c38fc37","placeholder":"‚Äã","style":"IPY_MODEL_5a8e16835a9444298b9d8533e4fc14f1","value":"‚Äá2.20k/2.20k‚Äá[00:00&lt;00:00,‚Äá55.8kB/s]"}},"ed02dd976db144b8be813d09c7bf25cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a5d0c88d7d74d95aae87f4e6fee4825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae81904f118c42a897175ca1b17f9369":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23d8011b8825449d8b8804cd7de0e512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68a82ce9b9ed4605bff67569ab9d0456":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0647de13fa344a8fb48acfa61c38fc37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8e16835a9444298b9d8533e4fc14f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U transformers\n!pip install rouge-score nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:42:45.102956Z","iopub.execute_input":"2025-06-15T18:42:45.103212Z","iopub.status.idle":"2025-06-15T18:43:06.070213Z","shell.execute_reply.started":"2025-06-15T18:42:45.103192Z","shell.execute_reply":"2025-06-15T18:43:06.069207Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"IyL9gZJmryPA","outputId":"cdb18989-81ba-4e2d-cb93-90d85943d55b"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nCollecting transformers\n  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.3\n    Uninstalling transformers-4.51.3:\n      Successfully uninstalled transformers-4.51.3\nSuccessfully installed transformers-4.52.4\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=75b18a0cefa96e7758076ba165d8e0b319dd90f203b2535b17e88bacef4e4775\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Model page: https://huggingface.co/google/flan-t5-base\n\n‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/google/flan-t5-base)\n\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè","metadata":{"id":"joVSugjCryPA"}},{"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, TFT5ForConditionalGeneration\nfrom rouge_score import rouge_scorer\nfrom nltk.translate.bleu_score import sentence_bleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:43:06.071576Z","iopub.execute_input":"2025-06-15T18:43:06.071925Z","iopub.status.idle":"2025-06-15T18:43:34.446697Z","shell.execute_reply.started":"2025-06-15T18:43:06.071884Z","shell.execute_reply":"2025-06-15T18:43:34.446047Z"},"id":"UieOAwLJryPC"},"outputs":[{"name":"stderr","text":"2025-06-15 18:43:08.000160: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1750012988.212636      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1750012988.267024      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_parquet(\"hf://datasets/eagle0504/warren-buffett-letters-qna-r1-enhanced-1998-2024/data/train-00000-of-00001.parquet\")","metadata":{"trusted":true,"id":"G8Ho6IEpryPC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6ae24991-21a6-4b29-e6cd-450e6fc1a01e","execution":{"iopub.status.busy":"2025-06-15T18:43:34.449098Z","iopub.execute_input":"2025-06-15T18:43:34.449959Z","iopub.status.idle":"2025-06-15T18:43:35.879153Z","shell.execute_reply.started":"2025-06-15T18:43:34.449936Z","shell.execute_reply":"2025-06-15T18:43:35.878471Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Qlwhpq6NryPD","outputId":"4d07941c-98b4-4f9f-abf9-701eecb08ef4","execution":{"iopub.status.busy":"2025-06-15T18:43:35.879931Z","iopub.execute_input":"2025-06-15T18:43:35.880213Z","iopub.status.idle":"2025-06-15T18:43:35.906762Z","shell.execute_reply.started":"2025-06-15T18:43:35.880193Z","shell.execute_reply":"2025-06-15T18:43:35.906075Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  **\"How does Warren Buffett's principle of 'pra...   \n1  Here are a few strong questions worth asking b...   \n2  **\"How does Warren Buffett's principle of 'pra...   \n3  **\"How does Warren Buffett's principle of 'pra...   \n4  **\"How does Warren Buffett's principle of 'pra...   \n\n                                              answer  \\\n0  A good answer would be:  \\n\\n*Warren Buffett e...   \n1  A good answer would be:  \\n\\nWarren Buffett ac...   \n2  Here‚Äôs a concise answer derived from the parag...   \n3  A good answer would highlight Warren Buffett's...   \n4  A good answer would highlight Warren Buffett's...   \n\n                                           reasoning  \n0  The reasoning is as follows:  \\n\\n1. **Context...  \n1  Warren Buffett emphasizes transparency, accoun...  \n2  The reasoning is as follows:  \\n\\n1. **Context...  \n3  The reasoning is as follows:  \\n\\n1. **Context...  \n4  The reasoning is as follows:  \\n\\n1. **Context...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>reasoning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>**\"How does Warren Buffett's principle of 'pra...</td>\n      <td>A good answer would be:  \\n\\n*Warren Buffett e...</td>\n      <td>The reasoning is as follows:  \\n\\n1. **Context...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Here are a few strong questions worth asking b...</td>\n      <td>A good answer would be:  \\n\\nWarren Buffett ac...</td>\n      <td>Warren Buffett emphasizes transparency, accoun...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>**\"How does Warren Buffett's principle of 'pra...</td>\n      <td>Here‚Äôs a concise answer derived from the parag...</td>\n      <td>The reasoning is as follows:  \\n\\n1. **Context...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>**\"How does Warren Buffett's principle of 'pra...</td>\n      <td>A good answer would highlight Warren Buffett's...</td>\n      <td>The reasoning is as follows:  \\n\\n1. **Context...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>**\"How does Warren Buffett's principle of 'pra...</td>\n      <td>A good answer would highlight Warren Buffett's...</td>\n      <td>The reasoning is as follows:  \\n\\n1. **Context...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def preprocess_for_chatbot(text):\n    # Return empty string if the text is empty\n    if pd.isna(text):\n        return \"\"\n\n    text = str(text)\n\n    # Replaces escaped charecters for readability\n    text = text.replace(\"\\\\n\", \" \").replace(\"\\\\t\", \" \").replace(\"\\\\'\", \"'\").replace('\\\\\"', '\"')\n\n    # Use only the first question\n    questions = re.findall(r'\\*\\*\"([^\"]*?)\"\\*\\*', text)\n    if questions:\n        return questions[0].strip()\n\n    # Handle Markdown from the text\n    text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)  # **text** ‚Üí text\n    text = re.sub(r'\\*(.*?)\\*', r'\\1', text)      # *text* ‚Üí text\n\n    # Removes annotation in text .i.e (explanation)\n    text = re.sub(r'\\*\\([^)]*\\)\\*', '', text)\n\n    # Makes sure the spacing is uniform\n    text = re.sub(r'\\s+', ' ', text).strip()\n\n    # Handle quotes\n    if text.startswith('\"') and text.endswith('\"') and text.count('\"') == 2:\n        text = text[1:-1].strip()\n\n    return text","metadata":{"trusted":true,"id":"Asa0a_AQryPD","execution":{"iopub.status.busy":"2025-06-15T18:43:35.907566Z","iopub.execute_input":"2025-06-15T18:43:35.907821Z","iopub.status.idle":"2025-06-15T18:43:35.915157Z","shell.execute_reply.started":"2025-06-15T18:43:35.907802Z","shell.execute_reply":"2025-06-15T18:43:35.914298Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocess_chatbot_dataset(df):\n    # Apply minimal cleaning\n    for col in ['question', 'reasoning', 'answer']:\n        if col in df.columns:\n            df[col] = df[col].apply(preprocess_for_chatbot)\n\n    # Remove empty entries\n    df = df.dropna(subset=['question', 'answer'])\n    df = df[df['question'].str.len() > 5]\n    df = df[df['answer'].str.len() > 10]\n\n    print(f\"Dataset ready: {len(df)} samples\")\n\n    # Show sample question and answer\n    if len(df) > 0:\n        print(f\"\\nSample preserved question:\")\n        print(f\"'{df['question'].iloc[0]}'\")\n        print(f\"\\nSample preserved answer:\")\n        print(f\"'{df['answer'].iloc[0]}'\")\n        print(f\"\\nSample preserved reasoning:\")\n        print(f\"'{df['reasoning'].iloc[0]}'\")\n\n    return df\n","metadata":{"trusted":true,"id":"sGmGb01FryPD","execution":{"iopub.status.busy":"2025-06-15T18:43:35.916275Z","iopub.execute_input":"2025-06-15T18:43:35.916607Z","iopub.status.idle":"2025-06-15T18:43:35.934926Z","shell.execute_reply.started":"2025-06-15T18:43:35.916574Z","shell.execute_reply":"2025-06-15T18:43:35.933963Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"clean_df = preprocess_chatbot_dataset(df)","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"l1u_tpNDryPE","outputId":"99784d8e-9478-4047-9c56-34df4e6fd041","execution":{"iopub.status.busy":"2025-06-15T18:43:35.935976Z","iopub.execute_input":"2025-06-15T18:43:35.936328Z","iopub.status.idle":"2025-06-15T18:43:37.290218Z","shell.execute_reply.started":"2025-06-15T18:43:35.936297Z","shell.execute_reply":"2025-06-15T18:43:37.289287Z"}},"outputs":[{"name":"stdout","text":"Dataset ready: 10657 samples\n\nSample preserved question:\n'How does Warren Buffett's principle of 'praise by name, criticize by category' reflect his broader philosophy on leadership and accountability?'\n\nSample preserved answer:\n'A good answer would be: Warren Buffett emphasizes the importance of transparency, accountability, and prompt corrective action when mistakes occur in business. He acknowledges that errors in capital allocation and personnel decisions are inevitable, but the real failure is in delaying fixes‚Äîwhat Charlie Munger called \"thumb-sucking.\" Unlike many corporations that avoid admitting mistakes, Buffett believes in openly discussing both successes and failures to maintain trust with shareholders.'\n\nSample preserved reasoning:\n'The reasoning is as follows: 1. Context from the Paragraph: Warren Buffett openly discusses Berkshire Hathaway's mistakes in capital allocation, personnel decisions, and delayed corrections, contrasting this transparency with other companies that avoid admitting errors. 2. Key Insight: Buffett emphasizes the importance of acknowledging mistakes (\"praise by name, criticize by category\") and acting on them, rather than ignoring problems (\"thumb-sucking\"). 3. Derived Answer: The answer highlights Buffett‚Äôs belief that admitting mistakes fosters trust and accountability, which aligns with his shareholder communication philosophy‚Äîtreating investors as he would want to be treated if roles were reversed. 4. Supporting Evidence: The paragraph mentions Buffett‚Äôs 16 admissions of \"mistake/error\" (unlike many companies) and references Amazon‚Äôs candidness, reinforcing that transparency is rare but valuable. Thus, the answer logically follows from Buffett‚Äôs stated principles and examples in the text.'\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def load_tokenizer(model_name=\"google/flan-t5-base\"):\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    return tokenizer\n","metadata":{"trusted":true,"id":"UXfPXQ05ryPE","execution":{"iopub.status.busy":"2025-06-15T18:43:37.291215Z","iopub.execute_input":"2025-06-15T18:43:37.291553Z","iopub.status.idle":"2025-06-15T18:43:37.295937Z","shell.execute_reply.started":"2025-06-15T18:43:37.291520Z","shell.execute_reply":"2025-06-15T18:43:37.295228Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def load_model(model_name=\"google/flan-t5-base\"):\n    model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n    return model","metadata":{"trusted":true,"id":"9GSLySfEryPE","execution":{"iopub.status.busy":"2025-06-15T18:43:37.298713Z","iopub.execute_input":"2025-06-15T18:43:37.299295Z","iopub.status.idle":"2025-06-15T18:43:37.313967Z","shell.execute_reply.started":"2025-06-15T18:43:37.299273Z","shell.execute_reply":"2025-06-15T18:43:37.313050Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def format_qa_pair(question, answer):\n    input_text = f\"Answer this financial question based on Warren Buffett's principles: {question}\"\n\n    target_text = answer\n    return input_text, target_text","metadata":{"trusted":true,"id":"3GILadT_ryPE","execution":{"iopub.status.busy":"2025-06-15T18:43:37.314926Z","iopub.execute_input":"2025-06-15T18:43:37.315188Z","iopub.status.idle":"2025-06-15T18:43:37.333487Z","shell.execute_reply.started":"2025-06-15T18:43:37.315170Z","shell.execute_reply":"2025-06-15T18:43:37.332629Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef split_train_val(df, val_size=0.2):\n    train_df, val_df = train_test_split(df, test_size=val_size, random_state=42)\n\n    return train_df, val_df","metadata":{"trusted":true,"id":"H1FURQvvryPF","execution":{"iopub.status.busy":"2025-06-15T18:43:37.334335Z","iopub.execute_input":"2025-06-15T18:43:37.334637Z","iopub.status.idle":"2025-06-15T18:43:37.350422Z","shell.execute_reply.started":"2025-06-15T18:43:37.334611Z","shell.execute_reply":"2025-06-15T18:43:37.349479Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import tensorflow as tf\n\ndef tokenize_data(df, tokenizer, batch_size=3):\n    inputs = []\n    labels = []\n    attention_masks = [] # Add attention mask\n\n    for index, row in df.iterrows():\n        # Tokenize question and get attention mask\n        question_tokens = tokenizer(row['question'], max_length=256, padding='max_length', truncation=True, return_tensors='tf')\n        inputs.append(question_tokens['input_ids'][0])\n        attention_masks.append(question_tokens['attention_mask'][0]) # Append attention mask\n\n        # Tokenize answer\n        answer_tokens = tokenizer(row['answer'], max_length=256, padding='max_length', truncation=True, return_tensors='tf')\n        labels.append(answer_tokens['input_ids'][0])\n\n\n    # Convert lists to tensors\n    inputs = tf.stack(inputs)\n    attention_masks = tf.stack(attention_masks) # Stack attention masks\n    labels = tf.stack(labels)\n\n    # Return as a dictionary\n    return tf.data.Dataset.from_tensor_slices({\n        'input_ids': inputs,\n        'attention_mask': attention_masks,\n        'labels': labels\n    }).batch(batch_size)","metadata":{"trusted":true,"id":"EI8C8kJ4ryPF","execution":{"iopub.status.busy":"2025-06-15T18:43:37.351263Z","iopub.execute_input":"2025-06-15T18:43:37.351544Z","iopub.status.idle":"2025-06-15T18:43:37.366817Z","shell.execute_reply.started":"2025-06-15T18:43:37.351519Z","shell.execute_reply":"2025-06-15T18:43:37.366060Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"tokenizer = load_tokenizer()\n\ntrain_df, val_df = split_train_val(df)\n\nprint(f\"Train samples: {len(train_df)}\")\nprint(f\"Val samples: {len(val_df)}\")","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":181,"referenced_widgets":["554213b2b5cf4dd386fda7fcc8d4c24c","cdaa3cf060034551bd054b307c7703a2","3c51de8e2b9d437895e1a1d4cfb6c0d6","d6ddc9d3673f4381816c6f5d2ecfe691","71438e4b1841460c9e39386559f5cf4b","91387783687b4e7088780aa6686daf3b","06635ee354384365a4975d92fb378421","d541d27dd79c470da7cc261526a0892b","3a0ce921159943a7a05fddcdcae02d6f","5604e41686924130b8c6eba9e07b772e","ea1a026e28174c6385fbe63116d1bd78","ff03ec31f7af47219ce89d0468327bb5","65f4fd5a19394a7195cb0af68bc85ce6","22896c1488fd483d9d06061d20df9646","b77e2c40c8cc42b5ab67013c749b5983","ccb3f76116e54a8e98613312520df7c3","e469446a24094c7c81f7ce3c09375470","b211e1844f9c4cae80a92c30816acea3","0e3af8ce958048c8a19fc789b17d31bd","c6a65407d9cd4249a6984136c786397e","dfd6efdcae014720b8926a2d422e6149","a1e8320468f8435fb210aff27537a29c","d5e3d779e0de4b7e89af4eb4b3affaf6","9915c4e538864e259c3bad7a53383155","4ca84fa7f5954de89f3494cc7ce6ba1d","974cfc5b71834335a408cbeccd2edb96","4fb8543c965c4a36a95822cbf582a7ec","3c297670187743d8bcc188d9c68b5153","ef2e676991a94b01a4353c3c1a880645","1f8c96aead8d40ce91fb8327a50193ed","dfcff02f3bbd4173b3426dd2207ae24e","c63ecf4d68784a31aeb4a21e1b33f1e1","8a20d607d042434f951f84ade04dac84","98ece805e48e45d4b9542c2257b0962f","b84eeb4bc02941e88ea9703f78718e78","f8455a470ec24de29af1dedf5539eb42","aaf375295e204c7e9c55f459ce73f07e","ed02dd976db144b8be813d09c7bf25cc","2a5d0c88d7d74d95aae87f4e6fee4825","ae81904f118c42a897175ca1b17f9369","23d8011b8825449d8b8804cd7de0e512","68a82ce9b9ed4605bff67569ab9d0456","0647de13fa344a8fb48acfa61c38fc37","5a8e16835a9444298b9d8533e4fc14f1"]},"id":"Dkyfiak8ryPF","outputId":"902f08e1-23c0-4e78-9c02-5892c51fe8da","execution":{"iopub.status.busy":"2025-06-15T18:43:37.367719Z","iopub.execute_input":"2025-06-15T18:43:37.368062Z","iopub.status.idle":"2025-06-15T18:43:38.626768Z","shell.execute_reply.started":"2025-06-15T18:43:37.368037Z","shell.execute_reply":"2025-06-15T18:43:38.625808Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de81f395f7f94566b052bdbcc7c7d697"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af0e091b4aa4e28854d5de31fc2ac6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0355c6dea2934706b77bba5f43a9917a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd4d0307d9042718ffe73861a19fd62"}},"metadata":{}},{"name":"stdout","text":"Train samples: 8525\nVal samples: 2132\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def train_model(train_dict, val_dict, learning_rate=5e-5, callbacks=[], epochs=25):\n    model = load_model()\n\n    # Compile with optimizer\n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n    model.compile(optimizer=optimizer)\n\n    # Train with proper dataset format\n    model.fit(\n        train_dict,\n        validation_data=val_dict,\n        epochs=epochs\n    )\n\n    return model","metadata":{"trusted":true,"id":"CNHZWGM-ryPF","execution":{"iopub.status.busy":"2025-06-15T18:43:38.627582Z","iopub.execute_input":"2025-06-15T18:43:38.627923Z","iopub.status.idle":"2025-06-15T18:43:38.636961Z","shell.execute_reply.started":"2025-06-15T18:43:38.627895Z","shell.execute_reply":"2025-06-15T18:43:38.635686Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_dict = tokenize_data(train_df, tokenizer)\nval_dict = tokenize_data(val_df, tokenizer)","metadata":{"trusted":true,"id":"rQfbsPm8ryPF","execution":{"iopub.status.busy":"2025-06-15T18:43:38.638304Z","iopub.execute_input":"2025-06-15T18:43:38.638982Z","iopub.status.idle":"2025-06-15T18:44:06.769607Z","shell.execute_reply.started":"2025-06-15T18:43:38.638947Z","shell.execute_reply":"2025-06-15T18:44:06.768703Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1750013018.841791      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def get_simple_callbacks():    \n    # TUNABLE CONSTANTS - Change these easily\n    PATIENCE = 1              \n    LR_REDUCTION_FACTOR = 0.5 \n    LR_PATIENCE = 2           \n    MIN_LR = 1e-7            \n    MIN_DELTA = 0.01         \n    RESTORE_BEST = True\n    \n    callbacks = [\n        # Stop training if no improvement\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=PATIENCE,\n            restore_best_weights=RESTORE_BEST,\n            min_delta=MIN_DELTA,\n            verbose=1\n        ),\n        \n        # Reduce learning rate when stuck\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=LR_REDUCTION_FACTOR,\n            patience=LR_PATIENCE,\n            min_lr=MIN_LR,\n            verbose=1\n        ),\n        \n        # Save best model\n        tf.keras.callbacks.ModelCheckpoint(\n            filepath='./best_model',\n            monitor='val_loss',\n            save_best_only=True,\n            verbose=1\n        )\n    ]\n    \n    return callbacks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:44:06.770735Z","iopub.execute_input":"2025-06-15T18:44:06.771040Z","iopub.status.idle":"2025-06-15T18:44:06.777135Z","shell.execute_reply.started":"2025-06-15T18:44:06.770986Z","shell.execute_reply":"2025-06-15T18:44:06.776259Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"callbacks = get_simple_callbacks()\n\nmodel = train_model(train_dict, val_dict, callbacks=callbacks)","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"vt6MY891ryPF","outputId":"a902b88c-add6-4414-eadf-e278891ba89e","execution":{"iopub.status.busy":"2025-06-15T18:44:06.778047Z","iopub.execute_input":"2025-06-15T18:44:06.778349Z","iopub.status.idle":"2025-06-16T01:30:02.998024Z","shell.execute_reply.started":"2025-06-15T18:44:06.778323Z","shell.execute_reply":"2025-06-16T01:30:02.997291Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172edcc81bfa42ec9cc3c6df3c4c461e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67be085b9bb14589a9403cf6bcf8a475"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n  warnings.warn(\nAll PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n\nAll the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1750013148.763815     128 service.cc:148] XLA service 0x7f87d0036060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1750013148.764534     128 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1750013148.841986     128 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1750013149.025963     128 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"2842/2842 [==============================] - 1113s 351ms/step - loss: 1.1857 - val_loss: 0.7065\nEpoch 2/25\n2842/2842 [==============================] - 972s 342ms/step - loss: 0.7567 - val_loss: 0.6415\nEpoch 3/25\n2842/2842 [==============================] - 957s 337ms/step - loss: 0.5107 - val_loss: 0.4633\nEpoch 7/25\n2842/2842 [==============================] - 985s 347ms/step - loss: 0.4715 - val_loss: 0.4383\nEpoch 8/25\n2842/2842 [==============================] - 979s 345ms/step - loss: 0.4371 - val_loss: 0.4187\nEpoch 9/25\n2842/2842 [==============================] - 966s 340ms/step - loss: 0.4085 - val_loss: 0.4035\nEpoch 10/25\n2842/2842 [==============================] - 970s 341ms/step - loss: 0.3818 - val_loss: 0.3898\nEpoch 11/25\n2842/2842 [==============================] - 964s 339ms/step - loss: 0.3595 - val_loss: 0.3809\nEpoch 12/25\n2842/2842 [==============================] - 962s 339ms/step - loss: 0.3386 - val_loss: 0.3720\nEpoch 13/25\n2842/2842 [==============================] - 968s 341ms/step - loss: 0.3192 - val_loss: 0.3660\nEpoch 14/25\n2842/2842 [==============================] - 963s 339ms/step - loss: 0.3018 - val_loss: 0.3617\nEpoch 15/25\n2842/2842 [==============================] - 968s 340ms/step - loss: 0.2859 - val_loss: 0.3550\nEpoch 16/25\n2842/2842 [==============================] - 970s 341ms/step - loss: 0.2722 - val_loss: 0.3548\nEpoch 17/25\n2842/2842 [==============================] - 973s 342ms/step - loss: 0.2591 - val_loss: 0.3496\nEpoch 18/25\n2842/2842 [==============================] - 973s 342ms/step - loss: 0.2463 - val_loss: 0.3500\nEpoch 19/25\n2842/2842 [==============================] - 978s 344ms/step - loss: 0.2344 - val_loss: 0.3476\nEpoch 20/25\n2842/2842 [==============================] - 970s 341ms/step - loss: 0.2235 - val_loss: 0.3479\nEpoch 21/25\n2842/2842 [==============================] - 965s 340ms/step - loss: 0.2134 - val_loss: 0.3487\nEpoch 22/25\n2842/2842 [==============================] - 964s 339ms/step - loss: 0.2034 - val_loss: 0.3459\nEpoch 23/25\n2842/2842 [==============================] - 975s 343ms/step - loss: 0.1937 - val_loss: 0.3431\nEpoch 24/25\n2842/2842 [==============================] - 969s 341ms/step - loss: 0.1851 - val_loss: 0.3472\nEpoch 25/25\n2842/2842 [==============================] - 967s 340ms/step - loss: 0.1767 - val_loss: 0.3525\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"question = \"What philosophy do you use when deciding if a company is valuable?\"","metadata":{"trusted":true,"id":"Vr5TT4rrryPF","execution":{"iopub.status.busy":"2025-06-16T01:30:02.998970Z","iopub.execute_input":"2025-06-16T01:30:02.999303Z","iopub.status.idle":"2025-06-16T01:30:03.003656Z","shell.execute_reply.started":"2025-06-16T01:30:02.999283Z","shell.execute_reply":"2025-06-16T01:30:03.002879Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Make a prediction\ndef predict_answer(question, model, tokenizer):\n    # Format the input similar to training\n    input_text = f\"Answer this financial question based on Warren Buffett's principles: {question}\"\n\n    # Tokenize the input\n    input_tokens = tokenizer(input_text, return_tensors=\"tf\", max_length=256, padding='max_length', truncation=True)\n\n    # Generate the answer\n    generated_tokens = model.generate(\n        input_tokens[\"input_ids\"],\n        attention_mask=input_tokens[\"attention_mask\"],\n        max_length=256,\n        num_beams=4,\n        early_stopping=True\n    )\n\n    # Decode the generated tokens back to text\n    predicted_answer = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n\n    return predicted_answer\n\npredicted_answer = predict_answer(question, model, tokenizer)\nprint(f\"\\nQuestion: {question}\")\nprint(f\"Predicted Answer: {predicted_answer}\")","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"eZPIakPR34uX","outputId":"8643ee5e-eebb-405c-ffa1-64b859916a86","execution":{"iopub.status.busy":"2025-06-16T01:30:03.004607Z","iopub.execute_input":"2025-06-16T01:30:03.004900Z","iopub.status.idle":"2025-06-16T01:31:17.830435Z","shell.execute_reply.started":"2025-06-16T01:30:03.004880Z","shell.execute_reply":"2025-06-16T01:31:17.829767Z"}},"outputs":[{"name":"stdout","text":"\nQuestion: What philosophy do you use when deciding if a company is valuable?\nPredicted Answer: Here‚Äôs a strong answer derived from the paragraph and question: \"Warren Buffett values businesses with long-term competitive advantages in stable industries, even if they have low organic growth, because they generate high returns on invested capital and free cash flow that can be reinvested elsewhere. He emphasizes transparency in reporting so shareholders can make informed decisions, and he highlights Berkshire Hathaway‚Äôs transparency about acquisitions and investments, which aligns with his philosophy of avoiding misleading metrics like EBITDA.\"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def calculate_bleu(reference, candidate):\n    \"\"\"BLEU score for text similarity\"\"\"\n    reference_tokens = reference.split()\n    candidate_tokens = candidate.split()\n    return sentence_bleu([reference_tokens], candidate_tokens)","metadata":{"trusted":true,"id":"1s4LfG6z34uY","execution":{"iopub.status.busy":"2025-06-16T01:31:17.831164Z","iopub.execute_input":"2025-06-16T01:31:17.831365Z","iopub.status.idle":"2025-06-16T01:31:17.835825Z","shell.execute_reply.started":"2025-06-16T01:31:17.831350Z","shell.execute_reply":"2025-06-16T01:31:17.834948Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def calculate_rouge(reference, candidate):\n    \"\"\"ROUGE score for text quality\"\"\"\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    scores = scorer.score(reference, candidate)\n    return {\n        'rouge1': scores['rouge1'].fmeasure,\n        'rouge2': scores['rouge2'].fmeasure,\n        'rougeL': scores['rougeL'].fmeasure\n    }","metadata":{"trusted":true,"id":"9QFcp45c34uY","execution":{"iopub.status.busy":"2025-06-16T01:31:17.836780Z","iopub.execute_input":"2025-06-16T01:31:17.837082Z","iopub.status.idle":"2025-06-16T01:31:17.852652Z","shell.execute_reply.started":"2025-06-16T01:31:17.837061Z","shell.execute_reply":"2025-06-16T01:31:17.851861Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import math\n\ndef calculate_perplexity(model, tokenizer, text, max_length=256):\n    try:\n        inputs = tokenizer(text, return_tensors='tf', max_length=max_length, truncation=True)\n        input_ids = inputs['input_ids']\n        outputs = model(input_ids, labels=input_ids)\n        loss = outputs.loss\n        perplexity = math.exp(loss.numpy())\n        return perplexity\n    except:\n        return float('inf')","metadata":{"id":"pmW0JoeYEVRA","trusted":true,"execution":{"iopub.status.busy":"2025-06-16T01:31:17.853480Z","iopub.execute_input":"2025-06-16T01:31:17.853751Z","iopub.status.idle":"2025-06-16T01:31:17.867730Z","shell.execute_reply.started":"2025-06-16T01:31:17.853722Z","shell.execute_reply":"2025-06-16T01:31:17.866876Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def evaluate_model(model, tokenizer, test_df, sample_number=10):\n    bleu_scores = []\n    rouge_scores = []\n    perplexity_scores = []\n\n    test_df = test_df.sample(n=sample_number, random_state=42)\n\n    for _, row in test_df.iterrows():\n        # Generate prediction\n        input_text = f\"Answer this financial question based on Warren Buffett's principles: {row['question']}\"\n        inputs = tokenizer.encode(input_text, return_tensors='tf')\n        outputs = model.generate(inputs, max_length=200)\n        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n        # Calculate metrics\n        bleu = calculate_bleu(row['answer'], prediction)\n        rouge = calculate_rouge(row['answer'], prediction)\n        perplexity = calculate_perplexity(model, tokenizer, row['answer'])\n\n        bleu_scores.append(bleu)\n        rouge_scores.append(rouge)\n        perplexity_scores.append(perplexity)\n\n    # Filter out infinite perplexities\n    valid_perplexities = [p for p in perplexity_scores if p != float('inf')]\n\n    # Average scores\n    avg_bleu = np.mean(bleu_scores)\n    avg_rouge1 = np.mean([r['rouge1'] for r in rouge_scores])\n    avg_rouge2 = np.mean([r['rouge2'] for r in rouge_scores])\n    avg_rougeL = np.mean([r['rougeL'] for r in rouge_scores])\n    avg_perplexity = np.mean(valid_perplexities) if valid_perplexities else float('inf')\n\n    print(f\"BLEU Score: {avg_bleu:.4f}\")\n    print(f\"ROUGE-1: {avg_rouge1:.4f}\")\n    print(f\"ROUGE-2: {avg_rouge2:.4f}\")\n    print(f\"ROUGE-L: {avg_rougeL:.4f}\")\n    print(f\"Perplexity: {avg_perplexity:.2f}\")\n\n    return {\n        'bleu': avg_bleu,\n        'rouge1': avg_rouge1,\n        'rouge2': avg_rouge2,\n        'rougeL': avg_rougeL,\n        'perplexity': avg_perplexity\n    }","metadata":{"trusted":true,"id":"4MGAR0Ao34uY","execution":{"iopub.status.busy":"2025-06-16T01:31:17.869250Z","iopub.execute_input":"2025-06-16T01:31:17.869937Z","iopub.status.idle":"2025-06-16T01:31:17.884123Z","shell.execute_reply.started":"2025-06-16T01:31:17.869915Z","shell.execute_reply":"2025-06-16T01:31:17.883224Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"metrics = evaluate_model(model, tokenizer, val_df)","metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"XbFGUsI034uY","outputId":"46a00d0d-73f0-44a7-af9a-e6f8bf213823","execution":{"iopub.status.busy":"2025-06-16T01:31:17.885061Z","iopub.execute_input":"2025-06-16T01:31:17.885322Z","iopub.status.idle":"2025-06-16T01:37:10.769258Z","shell.execute_reply.started":"2025-06-16T01:31:17.885295Z","shell.execute_reply":"2025-06-16T01:37:10.768392Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1110369969.py:9: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  perplexity = math.exp(loss.numpy())\n/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 3-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"BLEU Score: 0.1808\nROUGE-1: 0.4916\nROUGE-2: 0.2965\nROUGE-L: 0.3876\nPerplexity: 1.36\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from datetime import datetime\n\ndef save_model(model, tokenizer, name=\"my_model\"):\n    \"\"\"Simple save function with timestamp\"\"\"\n    timestamp = datetime.now().strftime(\"%m%d_%H%M\")\n    full_name = f\"{name}_{timestamp}\"\n    model.save_pretrained(f\"./models/{full_name}\")\n    tokenizer.save_pretrained(f\"./models/{full_name}\")\n    print(f\"Saved: {full_name}\")\n\nsave_model(model, tokenizer, name=\"finance_chatbot\")","metadata":{"id":"qqZr2nol8_fj","trusted":true,"execution":{"iopub.status.busy":"2025-06-16T01:37:10.770178Z","iopub.execute_input":"2025-06-16T01:37:10.770506Z","iopub.status.idle":"2025-06-16T01:37:13.867467Z","shell.execute_reply.started":"2025-06-16T01:37:10.770473Z","shell.execute_reply":"2025-06-16T01:37:13.866554Z"}},"outputs":[{"name":"stdout","text":"Saved: finance_chatbot_0616_0137\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}